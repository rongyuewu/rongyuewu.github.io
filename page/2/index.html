<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
</head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">rongyuewu</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://github.com/smackgg/hexo-theme-smackdown">smackdown</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">rongyuewu</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">rongyuewu</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-Spark性能调优：" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/05/01/Spark性能调优：/" class="article-date">
  	<time datetime="2018-05-01T13:29:30.000Z" itemprop="datePublished">2018-05-01</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/01/Spark性能调优：/">
        Spark性能调优
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Spark性能调优："><a href="#Spark性能调优：" class="headerlink" title="Spark性能调优："></a>Spark性能调优：</h1><h2 id="1-分配更多的资源-–-性能调优的王道"><a href="#1-分配更多的资源-–-性能调优的王道" class="headerlink" title="1.分配更多的资源  – 性能调优的王道"></a>1.分配更多的资源  – 性能调优的王道</h2><pre><code>真实项目里的脚本：
    bin/spark-submit \
    --class com.xx.xx \
    --num-executors 80 \
    --driver-memory 6g \
    --executor-cores 3 \
    --master yarn-cluster \
    --queue root.default \
    --conf spark.yarn.executor.memoryOverhead=2048 \
    --conf spark.core.connection.ack.waite.timeout=300 \
    /usr/xx/xx.jar \
    args
</code></pre><h6 id="分配资源之前，要先看机器能够给我们提供多少资源，并且最大化的利用这些资源才是最好的；"><a href="#分配资源之前，要先看机器能够给我们提供多少资源，并且最大化的利用这些资源才是最好的；" class="headerlink" title="分配资源之前，要先看机器能够给我们提供多少资源，并且最大化的利用这些资源才是最好的；"></a>分配资源之前，要先看机器能够给我们提供多少资源，并且最大化的利用这些资源才是最好的；</h6><pre><code>1.standalone模式：
    根据实际情况分配spark作业资源，比如每台机器4G，2个cpu，20台机器
2.spark-on-yarn模式：
    要看spark作业要提交到的资源队列，大概有多少资源？
</code></pre><h6 id="SparkContext、DAGScheduler、taskScheduler，会将我们的算子切割成大量的task提交到Application的executor上去执行-比如分配给其中一个的executor100个task，他的cpu只有2个，那么并行只能执行2个task，如果cpu为5个，那么久先执行5个再执行5个"><a href="#SparkContext、DAGScheduler、taskScheduler，会将我们的算子切割成大量的task提交到Application的executor上去执行-比如分配给其中一个的executor100个task，他的cpu只有2个，那么并行只能执行2个task，如果cpu为5个，那么久先执行5个再执行5个" class="headerlink" title="SparkContext、DAGScheduler、taskScheduler，会将我们的算子切割成大量的task提交到Application的executor上去执行,比如分配给其中一个的executor100个task，他的cpu只有2个，那么并行只能执行2个task，如果cpu为5个，那么久先执行5个再执行5个"></a>SparkContext、DAGScheduler、taskScheduler，会将我们的算子切割成大量的task提交到Application的executor上去执行,比如分配给其中一个的executor100个task，他的cpu只有2个，那么并行只能执行2个task，如果cpu为5个，那么久先执行5个再执行5个</h6><pre><code>a.增加executor的数量：
    如果executor的数量比较少，那么意味着可以并行执行的task的数量就比较少，
    就意味着Application的并行执行能力比较弱；
        比如：
            有3个executor，每个executor有2个cup core，
            那么能够并行执行的task就是6个，6个执行完换下一批6个
    增加executor的个数后，并行执行的task就会变多，性能得到提升
b.增加每个executor的cpu core
        比如：
            之前：3个exexutor，每个executor的cpu core为2个，那么并执行的task是6个
                 把cpu core增加到5个，那么并行执行的task就是15个，提高了性能
c.增加每个executor的内存量：
    1.如果需要对RDD进行cache，那么更多的内存就能缓存更多的数据，
      将更少的数据写入磁盘，甚至不写入磁盘，减少了磁盘IO。
    2.对于shuffle操作，reduce端会需要内存来存储拉取过来的数据进行聚合，如果内存不够，
      也会写入磁盘，增加executor内存，就会有更少的数据写入磁盘，较少磁盘IO，提高性能。
    3.对于task的执行，需要创建很多对象，如果内存比较小，可能导致JVM堆内存满了，
      然后频繁的GC，垃圾回收，minorGC和fullGC，速度会很慢，如果加大内存，
      带来更少的GC，速度提升。
</code></pre><h2 id="2-调节并行度"><a href="#2-调节并行度" class="headerlink" title="2.调节并行度"></a>2.调节并行度</h2><pre><code>并行度：spark作业中，各个stage的task个数，也就代表了saprk作业中各个阶段[stage]的并行度。
[spark作业，Application，jobs，action会触发一个job，每个job会拆成多个stage，发生shuffle的时候，会拆出一个stage]
</code></pre><h5 id="如果不调节并行度，导致并行度过低，会怎么样？？？"><a href="#如果不调节并行度，导致并行度过低，会怎么样？？？" class="headerlink" title="如果不调节并行度，导致并行度过低，会怎么样？？？"></a>如果不调节并行度，导致并行度过低，会怎么样？？？</h5><pre><code>比如：
    1.我们通过上面的分配好资源后，有50个executor，每个executor10G内存，每个executor有3个cpu core
      基本已经达到了集群或者yarn的资源上限
    2. 50个executor * 3个cpu = 150个task,即可以并行执行150个task；
      而我们设置的时候只设置了100个并行度的task，这时候每个executor分配到2个task，同时运行task的数量只有100个，导致每个executor剩下的1个cpu core在那空转，浪费资源。
    资源虽然够了，但是并行度没有和资源相匹配，导致分配下去的资源浪费掉了！！！
    **合理的并行度设置，应该要设置的足够大，大到完全合理的利用集群资源！而且减少了每个task要处理的数据量[比如150g的数据分别分发给100个task处理就是每个task处理1.5G，但是如果是150个task的话，每个task就处理1G]**
总结：
    a. task数量，至少设置成与Spark application的总cpu数相同(理想状态下，比如150个cpu core，分配150个task，差不多同时运行完毕)
    b.官方推荐做法：task的数量设置成 Spark application的cpu core的个数的3~5倍！！
      比如总共150个cpu core，设置成300~500个task
      为什么这么设置呢？？？
           实际情况下和理想状态下是不一样的，因为有些task运行的快，有些运行的慢，
           比如有些运行需要50s，有些需要几分钟运行完毕，如果刚好设置task数量和cpu core的数量相同，可能会导致资源的浪费；
           比如150个task，10个运行完了，还有140个在运行，那么势必会导致10个cpu core的闲置，
           所以如果设置task的数量为cpu数量的2~3倍，一旦有task运行完，另一个task就会立刻补上来，
           尽量让cpu core不要空闲，提升了spark作业运行效率，提升性能。

    c.如何设置一个 Spark application的并行度？？？
        SparkConf sc = new SparkConf()
                       .set(&quot;spark.default.parallelism&quot;,&quot;500&quot;);
</code></pre><h2 id="3-重构RDD架构及RDD持久化"><a href="#3-重构RDD架构及RDD持久化" class="headerlink" title="3.重构RDD架构及RDD持久化:"></a>3.重构RDD架构及RDD持久化:</h2><pre><code>默认情况下 RDD出现的问题：             
                                              RDD4
                                            /
           hdfs --&gt; RDD1 --&gt; RDD2 --&gt;RDD3
                                            \
                                              RDD5
    以上情况： 执行RDD4和RDD5的时候都会从RDD1到RDD2然后到RDD3，执行期间的算子操作，
    而不会说到RDD3的算子操作后的结果给缓存起来，所以这样很麻烦，
    出现了RDD重复计算的情况，导致性能急剧下降！
结论：
    对于要多次计算和使用的公共RDD,一定要进行持久化！
    持久化也就是：BlockManager将RDD的数据缓存到内存或者磁盘上，后续无论对这个RDD进行多少次计算，都只需要到缓存中取就ok了。
    持久化策略：
        rdd.persist(StorageLevel.xx()) 或者 cache
        1.优先会把数据缓存到内存中 -- StorageLevel.MEMORY_ONLY
        2.如果纯内存空间无法支撑公共RDD的数据时，就会优先考虑使用序列化的机制在纯内存中存储，
        将RDD中的每个partition中的数据序列化成一个大的字节数组，也就是一个对象，
        序列化后，大大减少了内存空间的占用。-- StorageLevel.MEMORY_ONLY_SER
            序列化唯一的缺点：在获取数据的时候需要反序列化
        3.如果序列化纯内存的方式还是导致OOM，内存溢出的话，那就要考虑磁盘的方式。
          内存+磁盘的普通方式(无序列化) -- StorageLevel.MEMORY_AND_DISK
        4.如果上面的还是无法存下的话，就用 内存+磁盘+序列化 -- StorageLevel.MEMORY_AND_DISK_SER
另：在机器内存**极度充足**的情况下，可以使用双副本机制，来持久化，保证数据的高可靠性
    如果机器宕机了，那么还有一份副本数据，就不用再次进行算子计算了。[锦上添花--一般不要这么做] -- StorageLevel.MEMORY_ONLY_SER_2
</code></pre><h3 id="4-广播大变量-sc-broadcast-rdd-collect"><a href="#4-广播大变量-sc-broadcast-rdd-collect" class="headerlink" title="4.广播大变量 [sc.broadcast(rdd.collect)]"></a>4.广播大变量 [sc.broadcast(rdd.collect)]</h3><pre><code>问题情景：
    当我们在写程序用到外部的维度表的数据进行使用的时候，程序默认会给每个task都发送相同的这个数据，
    如果这个数据为100M，如果我们有1000个task，100G的数据，通过网络传输到task，
    集群瞬间因为这个原因消耗掉100G的内存，对spark作业运行速度造成极大的影响，性能想想都很可怕！！！
解决方案：
    sc.broadcast(rdd.collect)
    分析原理：
        [BlockManager:负责管理某个executor上的内存和磁盘上的数据]
        广播变量会在Driver上有一份副本，当一个task使用到广播变量的数据时，会在自己本地的executor的BlockManager去取数据，
        发现没有，BlockManager就会到Driver上远程去取数据，并保存在本地，
        然后第二个task需要的时候来找BlockManager直接就可以找到该数据，
        executor的Blockmanager除了可以到Driver远程的取数据，
        还可能到邻近节点的BlockManager上去拉取数据，越近越好!
    举例说明：
        50个executor，1000个task，外部数据10M，
        默认情况下，1000个task，1000个副本，10G数据，网络传输，集群中10G的内存消耗
        如果使用广播，50个executor，500M的数据，网络传输速率大大增加，
        10G=10000M 和 500M的对比 20倍啊。。。
**之前的一个测试[真实]：
        没有经过任何调优的spark作业，运行下来16个小时，
        合理分配资源+合理分配并行度+RDD持久化，作业下来5个小时,
        非常重要的一个调优Shuffle优化之后，2~3个小时，
        应用了其他的性能调优之后，JVM调参+广播等等，30分钟
        16个小时 和 30分钟对比，太可怕了！！！性能调优真的真的很重要！！！
</code></pre><h3 id="5-Kryo序列化机制："><a href="#5-Kryo序列化机制：" class="headerlink" title="5.Kryo序列化机制："></a>5.Kryo序列化机制：</h3><p>默认情况下，Spark内部使用java的序列化机制</p>
<pre><code>ObjectOutPutStream/ObjectInputStream,对象输入输出流机制来进行序列化
这种序列化机制的好处：
    处理方便，只是需要在算子里使用的变量是实现Serializable接口即可
缺点在于：
    默认序列化机制效率不高，序列化的速度比较慢，序列化后的数据占用内存空间还比较大
</code></pre><p> 解决：手动进行序列化格式的优化：Kryo [spark支持的]</p>
<pre><code>Kryo序列化机制比默认的java序列化机制速度快，
序列化后的数据更小，是java序列化后数据的 1/10 。
所以Kryo序列化后，会让网络传输的数据更少，在集群中耗费的资源大大减少。

Kryo序列化机制：[一旦启用，会生效的几个地方]
    a.算子函数中使用到的外部变量[比如广播的外部维度表数据]
        优化网络传输性能，较少集群的内存占用和消耗
    b.持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER
        将每个RDD partition序列化成一个大的字节数组时，就会使用Kryo进一步优化序列化的效率和性能。
        持久化RDD占用的内存越少，task执行的时候，创建的对象，不至于频繁的占满内存，频繁的GC
    c.shuffle
        在stage间的task的shuffle操作时，节点与节点之间的task会通过网络拉取和传输数据，
        此时这些数据也是可能需要序列化的，就会使用Kryo
</code></pre><p> 实现Kryo：</p>
<pre><code>step1. 在SparkConf里设置 new SparkConf()
                       .set(&quot;spark.serializer&quot;,&quot;org.apache.spark.serializer.KyroSerializer&quot;)
                       .registerKryoClasses(new Class[]{MyCategory.class})
    [Kryo之所以没有没有作为默认的序列化类库，就是因为Kryo要求，如果要达到它的最佳效果的话]
    [一定要注册我们自定义的类，不如：算子函数中使用到了外部自定义的对象变量，这时要求必须注册这个类，否则Kyro就达不到最佳性能]
step2. 注册使用到的，需要Kryo序列化的一些自定义类
</code></pre><h3 id="6-使用FastUtil优化数据格式："><a href="#6-使用FastUtil优化数据格式：" class="headerlink" title="6.使用FastUtil优化数据格式："></a>6.使用FastUtil优化数据格式：</h3><p>FastUtil是什么？？</p>
<pre><code>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；
fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set，
fastutil的每一种集合类型，都实现了对应的Java中的标准接口（比如fastutil的map，实现了Java的Map接口），因此可以直接放入已有系统的任何代码中。 
fastutil还提供了一些JDK标准类库中没有的额外功能（比如双向迭代器）。 
fastutil除了对象和原始类型为元素的集合，fastutil也提供引用类型的支持，但是对引用类型是使用等于号（=）进行比较的，而不是equals()方法。 
fastutil尽量提供了在任何场景下都是速度最快的集合类库。
</code></pre><p>Spark中FastUtil运用的场景？？</p>
<pre><code>1.如果算子函数使用了外部变量，
    第一可以使用broadcast广播变量优化；
    第二可以使用Kryo序列化类库，提升序列化性能和效率；
    第三如果外部变量是某种比较大的集合(Map、List等)，可以考虑fastutil来改写外部变量，
        首先从源头上就减少了内存的占用，通过广播变量进一步减少内存占用，
        再通过Kryo类库进一步减少内存占用
    避免了executor内存频繁占满，频繁唤起GC，导致性能下降的现象
</code></pre><p>使用步骤：</p>
<pre><code>step1:导入pom依赖
    &lt;dependency&gt;
        &lt;groupId&gt;fastutil&lt;/groupId&gt;
            &lt;artifactId&gt;fastutil&lt;/artifactId&gt;
        &lt;version&gt;5.0.9&lt;/version&gt;
    &lt;/dependency&gt;
step2:
    List&lt;Integer&gt; =&gt; IntList
     基本都是类似于IntList的格式，前缀就是集合的元素类型，
     特殊的就是Map，Int2IntMap，代表了Key-Value映射的元素类型
</code></pre><h3 id="7-调节数据本地化等待时长"><a href="#7-调节数据本地化等待时长" class="headerlink" title="7.调节数据本地化等待时长:"></a>7.调节数据本地化等待时长:</h3><p>问题发生的场景：</p>
<pre><code>spark在Driver上，对Application的每一个stage的task分配之前，
都会计算出每个task要计算的是哪个分片数据，RDD的某个partition；
spark的分配算法：
    a.优先把每一个task正好分配到他要计算的数据所在的节点，这样的话不用在网络间传输数据
    b.但是，task没有机会分配到数据所在的节点上，为什么呢？？？
        因为那个节点上的计算资源和计算能力都满了，这个时候 spark会等待一段时间，
        默认情况下是3s钟，到最后，实在等不了了，就会选择一个较差的本地化级别，
        比如说会把task分配到靠他要计算的数据的节点最近的节点，然后进行计算
    c.对于b来说肯定要发生网络传输，task会通过其所在节点的executor的BlockManager来获取数据，
    BlockManager发现自己本地没有，就会用getRemote()的方法，通过TransferService(网络数据传输组件)
    从数据所在节点的BlockManager中获取数据，通过网络传输给task所在的节点
总结：
  我们肯定是希望看到 task和数据都在同一个节点上，直接从本地的executor中的BlockManager中去获取数据，
  纯内存或者带点IO，如果通过网络传输，那么大量的网络传输和磁盘IO都是性能的杀手
</code></pre><p>本地化的级别类型：</p>
<pre><code>1.PROCESS_LOCAL: 进程本地化,代码和数据都在同一个进程中，也就是在同一个executor进程中，
  task由executor来执行，数据在executor的BlockManager中，性能最好
2.NODE_LOCAL: 节点本地化，比如说一个节点上有两个executor，其中一个task需要第一个executor的数据，
  但是他被分配给了第二个executor，他会找第二个executor的BlockManager去取数据，但是没有，
  BlockManager会去第一个的executor的BlockManager去取数据，这是发生在进程中的
3.NOPREF: 数据从哪里获取都一样，没有好坏之分
4.RACK_LOCAL: 数据在同一个机架上的不同节点上，需要进行网络间的数据传输
5.ANY: 数据可能在集群中的任何地方，而且不在同一个机架，这种性能最差！！
</code></pre><p>开发时的流程：</p>
<pre><code>观察spark作业时的日志，先测试，先用client模式，在本地就可以看到比较全的日志。
日志里面会显示：starting task...,PROCESS_LOCAL,或者是NODE_LOCAL，观察大部分数据本地化的级别
如果发现大部分都是PROCESS_LOCAL的级别，那就不用调了，如果大部分都是NODE_LOCAL或者ANY，那就要调节一下等待时长了
要反复调节，反复观察本地化级别是否提升，查看spark作业运行的时间有没有缩短
不要本末倒置，如果是 本地化级别提升了，但是因为大量的等待时间，spark作业的运行时常变大了，这就不要调节了
spark.locality.waite
spark.locality.waite.process
spark.locality.waite.node
spark.locality.waite.rack
默认等待时长都是3s
设置方法：
    new SparkConf().set(&quot;spark.locality.waite&quot;,&quot;10&quot;)//不要带s
</code></pre><h3 id="8-JVM调优：1个executor对应1个JVM进程"><a href="#8-JVM调优：1个executor对应1个JVM进程" class="headerlink" title="8.JVM调优：1个executor对应1个JVM进程"></a>8.JVM调优：1个executor对应1个JVM进程</h3><p>A. 降低cache操作的内存占比</p>
<pre><code>JVM模块：
    每一次存放对象的时候都会放入eden区域，其中有一个survivor区域，另一个survivor区域是空闲的[新生代]，
    当eden区域和一个survivor区域放满了以后(spark运行产生的对象太多了)，
    就会触发minor gc，小型垃圾回收，把不再使用的对象从内存中清空，给后面新创建的对象腾出空间
    清理掉了不在使用的对象后，还有一部分存活的对象(还要继续使用的对象)，
    将存活的对象放入空闲的那个survivor区域里，这里默认eden:survivor1: survivor2 = 8:1:1,
    假如对象占了1.5放不下survivor区域了，那么就会放到[老年代]里；
    假如JVM的内存不够大的话，可能导致频繁的新生代内存满溢，频繁的进行minor gc，
    频繁的minor gc会导致短时间内，有些存活的对象，多次垃圾回收都没有回收掉，
    会导致这种短生命周期的对象(其实是不一定要长期使用的对象)年龄过大，
    垃圾回收次数太多，还没有回收到，就已经跑到了老年代；
    老年代中可能会因为内存不足，囤积一大堆短生命周期的对象(本来应该在年轻代中的)，
    可能马上就要回收掉的对象，此时可能造成老年代内存满溢，造成频繁的full gc(全局/全面垃圾回收)，full gc就会去老年代中回收对象；
    由于full gc算法的设计，是针对老年代中的对象，数量很少，满溢进行full gc的频率应该很少，
    因此采取了不太复杂的但是耗费性能和时间的垃圾回收算法。full gc 很慢很慢；
    full gc 和 minor gc，无论是快还是慢，都会导致JVM的工作线程停止工作，即 stop the world，
    简言之：gc的时候，spark停止工作，等待垃圾回收结束;
在spark中，堆内存被分为了两块：
    一块是专门用来给RDD cache和persist操作进行RDD数据缓存用的；
    一块是给spark算子函数的运行使用的，存放函数中自己创建的对象；
默认情况下，给RDD cache的内存占比是60%,但是在某些情况下，比如RDD cache不那么紧张，
而task算子函数中创建的对象过多，内存不太大，导致频繁的minor gc，甚至频繁的full gc，
导致spark频繁的暂停工作，性能影响会非常大，
解决办法：
    集群是spark-onyarn的话就可以通过spark ui来查看，spark的作业情况，
    可以看到每个stage的运行情况，包括每个task的运行时间，gc时间等等，
    如果发现gc太频繁，时间太长，此时可以适当调节这个比例；
总结：
    降低cache的内存占比，大不了用persist操作，选择将一部分的RDD数据存入磁盘，
    或者序列化方式Kryo，来减少RDD缓存的内存占比；
    对应的RDD算子函数的内存占比就增多了，就可以减少minor gc的频率，同时减少full gc的频率，提高性能
具体实现：0.6-&gt;0.5-&gt;0.4-&gt;0.2
    new SparkConf().set(&quot;spark.storage.memoryFraction&quot;,&quot;0.5&quot;)
</code></pre><p>B. executor堆外内存与连接时常</p>
<pre><code>1. executor堆外内存[off-heap memory]:
   场景：
        比如两个stage，第二个stage的executor的task需要第一个executor的数据，
        虽然可以通过Driver的MapOutputTracker可以找到自己数据的地址[也就是第一个executor的BlockManager]，
        但是第一个executor已经挂掉了，关联的BlockManager也没了，就没办法获取到数据；

    有时候，如果你的spark作业处理的数据量特别大，几亿数据量；
    spark作业一运行，是不是报错诸如：shuffle file cannot find,executor task lost,out of memory,
    这时候可能是executor的堆外内存不够用了，导致executor在运行的时候出现了内存溢出；
    导致后续的stage的task在运行的时候，可能从一些executor中拉取shuffle map output 文件，
    但是executor已经挂掉了，关联的BlockManager也没有了，所以可能会报shuffle output file not found，resubmitting task，executor lost，spark作业彻底失败；
  这个时候就可以考虑调节executor的堆外内存，堆外内存调节的比较大的话，也会提升性能；

    怎么调价堆外内存的大小？？
        在spark-submit 的脚本中添加 
                    --conf spark.yarn.executor.memoryOverhead=2048
        注意：这个设置是在spark-submit脚本中，不是在 new SparkConf()里设置的！！！
        这个是在spark-onyarn的集群中设置的，企业也是这么设置的！
        默认情况下,堆外内存是300多M，我们在项目中通常都会出现问题，导致spark作业反复崩溃，
        我们就可以调节这个参数 ，一般来说至少1G(1024M)，有时候也会2G、4G，
        来避免JVM oom的异常问题，提高整体spark作业的性能
2. 连接时常的等待：
          知识回顾：如果JVM处于垃圾回收过程，所有的工作线程将会停止，相当于一旦进行垃圾回收，
          spark/executor就会停止工作，无法提供响应
   场景：
          通常executor优先会从自己关联的BlockManager去取数据，如果本地没有，
          会通过TransferService，去远程连接其他节点上的executor的BlockManager去取；
          如果这个远程的executor正好创建的对象特别大，特别多，频繁的让JVM的内存满溢，进行垃圾回收，
          此时就没有反应，无法建立网络连接，会有卡住的现象。spark默认的网络连接超时时间是60s，
          如果卡住60秒都无法建立网络连接的话，就宣布失败；
          出现的现象：偶尔会出现，一串fileId诸如：hg3y4h5g4j5h5g5h3 not found，file lost，
          报错几次，几次都拉取不到数据的话，可能导致spark作业的崩溃！
          也可能会导致DAGScheduler多次提交stage，TaskScheduler反复提交多次task，
          大大延长了spark作业的运行时间
  解决办法：[注意是在shell脚本上不是在SparkConf上set！！]
          spark-submit 
                       --conf spark.core.connection.ack.waite.timeout=300
</code></pre><h2 id="9-shuffle调优"><a href="#9-shuffle调优" class="headerlink" title="9.shuffle调优"></a>9.shuffle调优</h2><pre><code>shuffle的概念以及场景
    什么情况下会发生shuffle？？
        在spark中，主要是这几个算子：groupByKey、reduceByKey、countByKey、join等
    什么是shuffle？
        a) groupByKey：把分布在集群中各个节点上的数据中同一个key，对应的values都集中到一块，
        集中到集群中的同一个节点上，更严密的说就是集中到一个节点上的一个executor的task中。
        集中一个key对应的values后才能交给我们处理，&lt;key,iterable&lt;value&gt;&gt;
          b) reduceByKey：算子函数对values集中进行reduce操作，最后变成一个value
          c) join  RDD&lt;key,value&gt;    RDD&lt;key,value&gt;,只要两个RDD中key相同的value都会到一个节点的executor的task中，供我们处理
      以reduceByKey为例：
</code></pre><p><img src="http://m.qpic.cn/psb?/V11BXxlE33Kp9F/62Boojghtc6iLB8KUOFgXQfCRbAwTZoOek9gr3ocl*o!/b/dDMBAAAAAAAA&amp;bo=YgrgAgAAAAADB6g!&amp;rf=viewer_4" alt=""></p>
<h4 id="9-1-shuffle调优之-map端合并输出文件"><a href="#9-1-shuffle调优之-map端合并输出文件" class="headerlink" title="9.1. shuffle调优之 map端合并输出文件"></a>9.1. shuffle调优之 map端合并输出文件</h4><pre><code>默认的shuffle对性能有什么影响？？
    实际生产环境的条件：
        100个节点，每个节点一个executor：100个executor，每个executor2个cpu core，
        总格1000个task，平均到每个executor是10个task；按照第二个stage的task个数和第一个stage的相同，
        那么每个节点map端输出的文件个数就是：10 * 1000 = 10000 个
        总共100个节点，总共map端输出的文件数：10000 * 100 = 100W 个
        100万个。。。太吓人了！！！
    shuffle中的写磁盘操作，基本上是shuffle中性能消耗最严重的部分，
    通过上面的分析可知，一个普通的生产环境的spark job的shuffle环节，会写入磁盘100万个文件，
    磁盘IO性能和对spark作业执行速度的影响，是极其惊人的！！
    基本上，spark作业的性能，都消耗在了shuffle中了，虽然不只是shuffle的map端输出文件这一部分，但是这也是非常大的一个性能消耗点。
怎么解决？
    开启map端输出文件合并机制：
        new SparkConf().set(&apos;spark.shuffle.consolidateFiles&apos;,&apos;true&apos;)
    实际开发中，开启了map端输出文件合并机制后，有什么变化？
        100个节点，100个executor，
        每个节点2个cpu core，
        总共1000个task，每个executor10个task，
        每个节点的输出文件个数：
            2*1000 = 2000 个文件
        总共输出文件个数：
            100 * 2000 = 20万 个文件
        相比开启合并之前的100万个，相差了5倍！！
合并map端输出文件，对spark的性能有哪些影响呢？
    1. map task写入磁盘文件的IO，减少：100万 -&gt; 20万个文件
    2. 第二个stage，原本要拉取第一个stage的task数量文件，1000个task，第二个stage的每个task都会拉取1000份文件，走网络传输；合并以后，100个节点，每个节点2个cpu，第二个stage的每个task只需要拉取 100 * 2 = 200 个文件，网络传输的性能大大增强
    实际生产中，使用了spark.shuffle.consolidateFiles后，实际的调优效果：
        对于上述的生产环境的配置，性能的提升还是相当可观的，从之前的5个小时 降到了 2~3个小时
总结：
    不要小看这个map端输出文件合并机制，实际上在数据量比较大的情况下，本身做了前面的优化，
    executor上去了 -&gt; cpu core 上去了 -&gt; 并行度（task的数量）上去了，但是shuffle没调优，
    这时候就很糟糕了，大量的map端输出文件的产生，会对性能有比较恶劣的影响 
</code></pre><h4 id="9-2-map端内存缓冲与reduce端内存占比"><a href="#9-2-map端内存缓冲与reduce端内存占比" class="headerlink" title="9.2. map端内存缓冲与reduce端内存占比"></a>9.2. map端内存缓冲与reduce端内存占比</h4><pre><code>spark.shuffle.file.buffer,默认32k
spark.shuffle.memoryFraction,占比默认0.2
调优的分量：
    map端内存缓冲和reduce端内存占比，网上对他俩说的是shuffle调优的不二之选，其实这是不对的，
    因为以实际的生产经验来说，这两个参数没那么重要，但是还是有一点效果的，
    就像是很多小的细节综合起来效果就很明显了，
</code></pre><p>原理：</p>
<pre><code>map：
    默认情况下，shuffle的map task输出到磁盘文件的时候，统一都会先写入每个task自己关联的一个内存缓冲区中，
    这个缓冲区默认大小是32k，每一次，当内存缓冲区满溢后，才会进行spill操作，溢写到磁盘文件中
reduce：
    reduce端task，在拉取数据之后，会用hashmap的数据格式来对每个key对应的values进行汇聚，
    针对每个key对应的value，执行我们自定义的聚合函数的代码，比如_+_,(把所有values相加)
    reduce task,在进行汇聚、聚合等操作的时候，实际上，使用的就是自己对应的executor的内存，
    executor(jvm进程，堆),默认executor内存中划分给reduce task进行聚合的比例是20%。
    问题来了，内存占比是20%，所以很有可能会出现，拉取过来的数据很多，那么在内存中，
    放不下，这个时候就会发生spill(溢写)到磁盘文件中取.
</code></pre><p>如果不调优会出现什么问题？？</p>
<pre><code>默认map端内存缓冲是32k，
默认reduce端聚合内存占比是20%
如果map端处理的数据比较大，而内存缓冲是固定的，会出现什么问题呢？
    每个task处理320k，32k的内存缓冲，总共向磁盘溢写10次，
    每个task处理32000k，32k的内存缓冲，总共向磁盘溢写1000次，
    这样就造成了多次的map端往磁盘文件的spill溢写操作，发生大量的磁盘IO，降低性能
map数据量比较大，reduce端拉取过来的数据很多，就会频繁的发生reduce端聚合内存不够用，
频繁发生spill操作，溢写到磁盘上去，这样一来，磁盘上溢写的数据量越大，
后面进行聚合操作的时候，很可能会多次读取磁盘中的数据进行聚合
默认情况下，在数据量比较大的时候，可能频繁的发生reduce端磁盘文件的读写；
这两点是很像的，而且有关联的，数据量变大，map端肯定出现问题，reduce也出现问题，
出的问题都是一样的，都是磁盘IO频繁，变多，影响性能
</code></pre><p>调优解决：</p>
<pre><code>我们要看spark UI，
    1. 如果公司用的是standalone模式，那么很简单，把spark跑起来，会显示sparkUI的地址，
    4040端口号，进去看，依次点击可以看到，每个stage的详情，有哪些executor，有哪些task，
    每个task的shuffle write 和 shuffle read的量，shuffle的磁盘和内存，读写的数据量
    2. 如果是yarn模式提交，从yarn的界面进去，点击对应的application，进入spark ui，查看详情
如果发现磁盘的read和write很大，就意味着要调节一下shuffle的参数，进行调优，
首先当然要考虑map端输出文件合并机制
   调节上面两个的参数，原则是：
      spark.shuffle.buffer，每次扩大一倍，然后看看效果，64k，128k
    spark.shuffle.memoryFraction,每次提高0.1，看看效果
不能调节的过大，因为你这边调节的很大，相对应的其他的就会变得很小，其他环节就会出问题
调节后的效果：
    map task内存缓冲变大了，减少了spill到磁盘文件的次数；
    reduce端聚合内存变大了，减少了spill到磁盘的次数，而且减少了后面聚合时读取磁盘的数量
    new SparkConf()
    .set(&quot;spark.shuffle.file.buffer&quot;,&quot;64&quot;)
    .set(&quot;spark.shuffle.file.memoryFraction&quot;,&quot;0.3&quot;)
</code></pre><h2 id="10-算子调优"><a href="#10-算子调优" class="headerlink" title="10.算子调优"></a>10.算子调优</h2><h5 id="1-算子调优之MapPartitons提升map的操作性能"><a href="#1-算子调优之MapPartitons提升map的操作性能" class="headerlink" title="1.算子调优之MapPartitons提升map的操作性能"></a>1.算子调优之MapPartitons提升map的操作性能</h5><pre><code>在spark中最近本的原则：每个task处理RDD中的每一个partition
优缺点对比：
    普通Map：
        优点：比如处理了一千条数据，内存不够了，那么就可以将已经处理的一千条数据从内存里面垃圾回收掉，
        或者用其他办法腾出空间；通常普通的map操作不会导致内存OOM异常；
        缺点：比如一个partition中有10000条数据，那么function会执行和计算一万次
    MapPartitions:
        优点：一个task仅仅会执行一次function，一次function接收partition中的所有数据
        只要执行一次就可以了，性能比较高
        缺点：对于大数据量来说，比如一个partition100万条数据，一次传入一个function后，
        可能一下子内存就不够了，但是又没办法腾出空间来，可能就OOM，内存溢出
那么什么时候使用MapPartitions呢？
    当数据量不太大的时候，都可以使用MapPartitions来操作，性能还是很不错的，
    不过也有经验表明用了MapPartitions后，内存直接溢出，
    所以在项目中自己先估算一下RDD的数据量，以每个partition的量，还有分配给executor的内存大小，
    可以试一下，如果直接OOM了，那就放弃吧，如果能够跑通，那就可以使用。
</code></pre><h5 id="2-算子调优之filter之后-filter-之后-用-coalesce来减少partition的数量"><a href="#2-算子调优之filter之后-filter-之后-用-coalesce来减少partition的数量" class="headerlink" title="2.算子调优之filter之后 filter 之后  用 coalesce来减少partition的数量"></a>2.算子调优之filter之后 filter 之后  用 coalesce来减少partition的数量</h5><pre><code>默认情况下，RDD经过filter之后，RDD中每个partition的数据量会不太一样，(原本partition里的数据量可能是差不多的)
问题：
    1.每一个partition的数据量变少了，但是在后面进行处理的时候，
    还是要和partition的数量一样的task数量去处理，有点浪费task计算资源
    2.每个partition的数据量不一样，后面会导致每个处理partition的task要处理的数据量不一样，
    这时候很容易出现**数据倾斜**
    比如说，有一个partition的数据量是100，而另一个partition的数据量是900，
    在task处理逻辑一样的情况下，不同task要处理的数据量可能差别就到了9倍，甚至10倍以上，
    同样导致速度差别在9倍或者10倍以上
    这样就是导致了有的task运行的速度很快，有的运行的很慢，这就是数据倾斜。
解决：
    针对以上问题，我们希望把partition压缩，因为数据量变小了，partition完全可以对应的变少，
    比如原来4个partition，现在可以变成2个partition，那么就只要用后面的2个task来处理，
    不会造成task资源的浪费(不必要针对只有一点点数据的partition来启动一个task进行计算)
    避免了数据倾斜的问题
</code></pre><h5 id="3-算子调优之使用foreachPartition优化写入数据库性能"><a href="#3-算子调优之使用foreachPartition优化写入数据库性能" class="headerlink" title="3.算子调优之使用foreachPartition优化写入数据库性能"></a>3.算子调优之使用foreachPartition优化写入数据库性能</h5><pre><code>默认的foreach有哪些缺点？
    首先和map一样，对于每条数据都要去调一次function，task为每个数据，都要去执行一次task；
    如果一个partition有100万条数据，就要调用100万次，性能极差！
    如果每条数据都要创建一个数据库连接，那么就要创建100万个数据库连接，
    但是数据库连接的创建和销毁都是非常耗性能的，虽然我们用了数据库连接池，只要创建固定数量的连接，
    还是得多次通过数据库连接，往数据库里(mysql)发送一条sql语句，mysql需要去执行这条sql语句，
    有100万条数据，那么就是要发送100万次sql语句；
用了foreachPartition以后，有哪些好处？
    1.对于我们写的函数就调用一次就行了，一次传入一个partition的所有数据
    2.主要创建或者获取一个数据库连接就可以了
    3.只要向数据里发送一条sql语句和一组参数就可以了
在实际开发中，我们都是清一色使用foreachPartition算子操作，
但是有个问题，跟mapPartitions操作一样，如果partition的数据量非常大，
比如真的是100万条，那几本就不行了！一下子进来可能会发生OOM，内存溢出的问题
一组数据的对比：
    生产环境中：
        一个partition中有1000条数据，用foreach，跟用foreachPartition，
        性能提高了2~3分；
数据库里是：
    for循环里preparestatement.addBatch
    外面是preparestatement.executeBatch
</code></pre><h5 id="4-算子调优之repartition解决SparkSQL低并行度的问题"><a href="#4-算子调优之repartition解决SparkSQL低并行度的问题" class="headerlink" title="4.算子调优之repartition解决SparkSQL低并行度的问题"></a>4.算子调优之repartition解决SparkSQL低并行度的问题</h5><pre><code>并行度： 我们是可以自己设置的
    1.spark.default.parallelism
    2.sc.textFile(),第二个参数传入指定的数量(这个方法用的非常少)
在生产环境中，我们是要自己手动设置一下并行度的，官网推荐就是在spark-submit脚本中，
指定你的application总共要启动多少个executor，100个，每个executor多少个cpu core，
2~3个，假设application的总cpu core有200个；
官方推荐设置并行度要是总共cpu core个数的2~3倍，一般最大值，所以是 600；
设置的这个并行度，在哪些情况下生效？哪些情况下不生效？
    1.如果没有使用SparkSQL(DataFrame)的话，那么整个spark应用的并行度就是我们设置的那个并行度
    2.如果第一个stage使用了SparkSQL从Hive表中查询了一些数据，然后做了一些transformatin的操作，
    接着做了一个shuffle操作(groupByKey)；下一个stage，在shuffle之后，做了一些transformation的操作
    如果Hive表对应了20个block，而我们自己设置的并行度是100，
    那么第一个stage的并行度是不受我们控制的，就只有20个task，第二个stage的才是我们设置的并行度100个
问题出在哪里了？
    SparkSQL 默认情况下，我们是没办法手动设置并行度的，所以可能造成问题，也可能不造成问题，
    SparkSQL后面的transformation算子操作，可能是很复杂的业务逻辑，甚至是很复杂的算法，
    如果SparkSQL默认的并行度设置的很少，20个，然后每个task要处理为数不少的数据量，
    还要执行很复杂的算法，这就导致第一个stage特别慢，第二个stage 1000个task，特别快！
解决办法：
    repartition：
        使用SparkSQL这一步的并行度和task的数量肯定是没办法改变了，但是可以将SparkSQL查出来的RDD，
        使用repartition算子进行重新分区，比如分多个partition，20 -&gt; 100个；
        然后从repartition以后的RDD，并行度和task数量，就会按照我们预期的来了，
        就可以避免在跟SparkSQL绑定在一起的stage中的算子，只能使用少量的task去处理大量数据以及复杂的算法逻辑
</code></pre><p>5.算子操作reduceByKey：</p>
<pre><code>reduceByKey相较于普通的shuffle操作(不如groupByKey)，他的一个特点就是会进行map端的本地聚合；
对map端给下个stage每个task创建的输出文件中，写数据之前，就会进行本地的combiner操作，也就是多每个key的value，都会执行算子函数(_+_)，减少了磁盘IO，较少了磁盘空间的占用,在reduce端的缓存也变少了
</code></pre><h2 id="11-troubleshooting之控制reduce端缓冲大小以避免内存溢出-OOM"><a href="#11-troubleshooting之控制reduce端缓冲大小以避免内存溢出-OOM" class="headerlink" title="11.troubleshooting之控制reduce端缓冲大小以避免内存溢出(OOM)"></a>11.troubleshooting之控制reduce端缓冲大小以避免内存溢出(OOM)</h2><pre><code>new SparkConf().set(&quot;spark.reducer.maxSizeInFlight&quot;,&quot;24&quot;) //默认是48M
Map端的task是不断地输出数据的，数据量可能是很大的，
    但是其reduce端的task，并不是等到Map端task将属于自己的那个分数据全部写入磁盘后，再去拉取的
    Map端写一点数据，reduce端task就会去拉取一小部分数据，立刻进行后面的聚合，算子函数的应用；
    每次reduce能够拉取多少数据，是由reduce端buffer来定，因为拉取过来的数据都是放入buffer中的，
    然后采用后面的executor分配的堆内存占比(0.2),去进行后续的聚合，函数操作
reduce端buffer 可能会出现什么问题？
    reduce端buffer默认是48M，也许大多时候，还没有拉取满48M，也许是10M，就计算掉了，
    但是有时候，Map端的数据量特别大，写出的速度特别快，reduce端拉取的时候，全部到达了自己缓冲的最大极限48M，全部填满，
    这个时候，再加上reduce端执行的聚合函数代码，可能会创建大量的对象，也许一下子内存就撑不住了，就会造成OOM，reduce端的内存就会造成内存泄漏
如何解决？
    这个时候，我们应该减少reduce端task缓冲的大小，我们宁愿多拉取几次，但是每次同时能拉取到reduce端每个task的数据量比较少，就不容易发生OOM，比如调成12M；
    在实际生产中，这种问题是很常见的，这是典型的以性能换执行的原理，
    reduce的缓冲小了，不容易造成OOM了，但是性能一定是有所下降的，你要拉取的次数多了，
    就会走更多的网络IO流，这时候只能走牺牲性能的方式了；
曾经一个经验：
    曾经写了一个特别复杂的spark作业，写完代码后，半个月就是跑步起来，里面各种各样的问题，
    需要进行troubleshooting，调节了十几个参数，其中里面就有reduce端缓冲的大小，最后，
    总算跑起来了！
</code></pre><h3 id="12-troubleshooting之解决JVM-GC导致的shuffle拉取文件失败："><a href="#12-troubleshooting之解决JVM-GC导致的shuffle拉取文件失败：" class="headerlink" title="12. troubleshooting之解决JVM GC导致的shuffle拉取文件失败："></a>12. troubleshooting之解决JVM GC导致的shuffle拉取文件失败：</h3><pre><code>过程：
    第一个stage的task输出文件的同时 ，会像Driver上记录这些数据信息，然后下一个stage的task想要得到上个stage的数据，
    就得像Driver所要元数据信息，然后去像上一个的stage的task生成的文件中拉取数据。
问题场景：
    在spark作业中，有时候经常出现一种情况，就是log日志报出：shuffle file not found..,
    有时候他会偶尔出现一次，有的时候出现一次后重新提交stage、task，重新执行一遍 就好了。
分析问题：
    executor在JVM进程中，可能内存不太够用，那么此时就很可能执行GC，minor gc 或者 full gc，
    总之一旦发生gc后，就会导致所有工作线程全部停止，比如BlockManager，基于netty的网络通信。
    第二个stage的task去拉取数据的时候，上一个executor正好在进行gc，就导致拉取了半天也没拉取到数据，
    那为什么第二次提交stage的时候，就又可以了呢？
        因为第二次提交的时候，上一个executor已经完成了gc。
解决：
    spark.shuffle.io.maxRetries 3[默认3次]
        shuffle 文件拉取时，如果没有拉取到，最多或者重试几次，默认3次
    spark.shuffle.io.retryWait 5s [默认5s]
        每一次重新拉取文件的时间间隔，默认5s
    默认情况下，第一个stage的executor正在漫长的full gc，第二个stage的executor尝试去拉取数据，
    结果没拉取到，这样会反复重试拉取3次，中间间隔时间5s，也就是总共15s，拉取不成功，就报 shuffle file not found
        我们可以增大上面两个参数的值：
            spark.shuffle.io.maxRetries 60次
            spark.shuffle.io.retryWait 60s
            最多可以忍受一个小时没有拉取到shuffle file，这只是一个设置最大的可能值，
            full gc 也不可能一个小时都没结束把，
            这样就解决了因为gc 而无法拉取到数据的问题
</code></pre><h3 id="13-troubleshooting之解决yarn-cluster模式的JVM栈内存溢出问题"><a href="#13-troubleshooting之解决yarn-cluster模式的JVM栈内存溢出问题" class="headerlink" title="13. troubleshooting之解决yarn-cluster模式的JVM栈内存溢出问题"></a>13. troubleshooting之解决yarn-cluster模式的JVM栈内存溢出问题</h3><pre><code>yarn-cluster运行流程：
    1.本地机器执行spark-submit脚本[yarn-cluster模式]，提交spark application给resourceManager
    2. resourceManager找到一个节点[nodeManager]启动applicationMaster[Driver进程]
    3. applicationMaster找resourceManager申请executor
    4. resourceManager分配container(内存+cpu)
    5. applicationMaster找到对应nodeManager申请启动executor
    6. nodeManager启动executor
    7. executor找applicationMaster进行反向注册
    到这里为止，applicationMaster(Driver)就知道自己有哪些资源可以用(executor)，
    然后就会去执行job，拆分stage，提交stage的task，进行task调度，
    分配到各个executor上面去执行。
yarn-client 和 yarn-cluster的区别：
    yarn-client模式Driver运行在本地机器上；yarn-cluster模式Driver是运行在yarn集群上的某个nodeManager节点上的；
    yarn-client模式会导致本地机器负责spark作业的调用，所以网卡流量会激增，yarn-cluster没有这个问题；
    yarnclient的Driver运行在本地，通常来说本地机器和yarn集群都不会在一个机房，所以性能不是特别好；
    yarn-cluster模式下，Driver是跟yarn集群运行在一个机房内，性能上也会好很好；
实践经验碰到的yarn-cluster的问题：
    有时候运行了包含spark sql的spark作业，可能会遇到 在yarn-client上运行好好地，在yarn-cluster模式下，
    可能无法提交运行，会报出JVM的PermGen(永久代)的内存溢出-OOM；
    Yarn-client模式下，Driver是运行在本地机器的，spark使用的JVM的PerGen的配置，是本地的spark-class文件，
    (spark客户端是默认有配置的),JVM的永久代大小默认是128M，这个是没问题的；
    但是在Yarn-cluster模式下，Driver是运行在yarn集群的某个节点上的，使用的是没有经过配置的默认设置82M(PerGen永久代大小)
    spark sql内部会进行很负责的sl语义解析、语法树的转换，特别复杂，在这种情况下，如果sql特别复杂，
    很可能会导致性能的消耗，内存的消耗，可能对PermGen永久代的内存占比就很大
    所以此时，如果对PermGen的内存占比需求多与82M，但是又小于128M，就会出现类似上面的情况，
    yarn-client可以正常运行因为他的默认permgen大小是128M，但是yarn-cluster的默认是82M，就会出现PermGen OOM -- PermGen out of memory
解决：
    spark-submit脚本中加入参数：
        --conf spark.driver.extraJavaOptions=&apos;-XX:PermSize=128M -XX:MxPermSize=256M&apos;
        这样就设置了永久代的大小默认128M，最大256M，那么这样的话，就可以保证spark作业不会出现上面的PermGen out of memory
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-storm的架构" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/05/01/storm的架构/" class="article-date">
  	<time datetime="2018-05-01T13:29:30.000Z" itemprop="datePublished">2018-05-01</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/01/storm的架构/">
        storm
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="storm"><a href="#storm" class="headerlink" title="storm"></a>storm</h1><p><img src="http://m.qpic.cn/psb?/V11BXxlE33Kp9F/t7Rbr8aYgIO4*9TbdsjJMgxTPY8JHwAmijtuJfP2rbo!/b/dEMBAAAAAAAA&amp;bo=wAY4BAAAAAADN.g!&amp;rf=viewer_4" alt=""></p>
<h3 id="Storm架构"><a href="#Storm架构" class="headerlink" title="Storm架构"></a>Storm架构</h3><pre><code>类似于Hadoop的架构，主从(Master/Slave)
Nimbus: 主
    集群的主节点，负责任务(task)的指派和分发、资源的分配
Supervisor: 从
    可以启动多个Worker，具体几个呢？可以通过配置来指定
    一个Topo可以运行在多个Worker之上，也可以通过配置来指定
    集群的从节点，(负责干活的)，负责执行任务的具体部分
    启动和停止自己管理的Worker进程
无状态，在他们上面的信息(元数据)会存储在ZK中
Worker: 运行具体组件逻辑(Spout/Bolt)的进程
=====================分割线===================
task： 
    Spout和Bolt
    Worker中每一个Spout和Bolt的线程称为一个Task
executor： spout和bolt可能会共享一个线程
</code></pre><h5 id="提交代码到集群："><a href="#提交代码到集群：" class="headerlink" title="提交代码到集群："></a>提交代码到集群：</h5><pre><code>storm jar /home/hadoop/lib/storm-1.0.jar com.bigdata.ClusterSumStormTopology
</code></pre><h5 id="storm-其他命令的使用"><a href="#storm-其他命令的使用" class="headerlink" title="storm 其他命令的使用"></a>storm 其他命令的使用</h5><pre><code>list
    Syntax: storm list
    List the running topologies and their statuses.
如何停止作业
    kill
        Syntax: storm kill topology-name [-w wait-time-secs]
</code></pre><p>并行度</p>
<pre><code>一个worker进程执行的是一个topo的子集
一个worker进程会启动1..n个executor线程来执行一个topo的component
一个运行的topo就是由集群中多台物理机上的多个worker进程组成

executor是一个被worker进程启动的单独线程，每个executor只会运行1个topo的一个component
task是最终运行spout或者bolt代码的最小执行单元

默认：
    一个supervisor节点最多启动4个worker进程  
    每一个topo默认占用一个worker进程         
    每个worker进程会启动一个executor        
    每个executor启动一个task   

Total slots:4  
Executors: 3   但是stormUI上是 spout + bolt = 2  why 3?
隐藏的acker 导致的
</code></pre><h5 id="通过代码对并行度的理解："><a href="#通过代码对并行度的理解：" class="headerlink" title="通过代码对并行度的理解："></a>通过代码对并行度的理解：</h5><pre><code>Config conf = new Config();
conf.setNumWorkers(2); // use two worker processes
topologyBuilder.setSpout(&quot;blue-spout&quot;, new BlueSpout(), 2); // set parallelism hint to 2
topologyBuilder.setBolt(&quot;green-bolt&quot;, new GreenBolt(), 2)
           .setNumTasks(4)
           .shuffleGrouping(&quot;blue-spout&quot;);topologyBuilder.setBolt(&quot;yellow-bolt&quot;, new YellowBolt(), 6)
           .shuffleGrouping(&quot;green-bolt&quot;);StormSubmitter.submitTopology(
    &quot;mytopology&quot;,
    conf,
    topologyBuilder.createTopology()
);

##解释：
conf.setNumWorkers(2) ---&gt;两个worker
setSpout(&quot;blue-spout&quot;, new BlueSpout(), 2)---&gt; 2个spout executor 对应默认的2个task
setBolt(&quot;green-bolt&quot;, new GreenBolt(), 2).setNumTasks(4) ---&gt; 2个executor 4个task(因为它指定了setNumTasks个数)

结果：
1个topology
2个workers  
2+2+2[2个worker 就有2个acker] = 6个executors  
2+4+2[2个worker 就有2个acker默认2个task] = 8个task
</code></pre><h5 id="修改正在运行的topology的并行度："><a href="#修改正在运行的topology的并行度：" class="headerlink" title="修改正在运行的topology的并行度："></a>修改正在运行的topology的并行度：</h5><pre><code>#Reconfigure the topology &quot;mytopology&quot; to use 5 worker processes,
#the spout &quot;blue-spout&quot; to use 3 executors 
#the bolt &quot;yellow-bolt&quot; to use 10 executors.

1.可以使用StormUI来rebalance the topology.
2.也可以使用命令行来修改：$ storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10
</code></pre><p>stream grouping分组策略内置[build-in]有8种：</p>
<pre><code>常用的有两种：
1.shuffle grouping 随机分配也就是轮询RoundRobin 这样不会造成数据倾斜
2.fileds grouping 比如按照字段hash取模分组 
如果想自定义分组策略：--&gt; 自定义分组策略需要实现CustomStreamGroup接口
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-HBASE：出自Google论文的发表" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/04/05/HBASE：出自Google论文的发表/" class="article-date">
  	<time datetime="2018-04-05T13:29:30.000Z" itemprop="datePublished">2018-04-05</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/05/HBASE：出自Google论文的发表/">
        HBASE总结：出自Google论文的发表
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="HBASE：出自Google论文的发表"><a href="#HBASE：出自Google论文的发表" class="headerlink" title="HBASE：出自Google论文的发表"></a>HBASE：出自Google论文的发表</h2><h6 id="列式存储、多版本-timestamp-的、nosql数据库"><a href="#列式存储、多版本-timestamp-的、nosql数据库" class="headerlink" title="[列式存储、多版本(timestamp)的、nosql数据库]"></a>[列式存储、多版本(timestamp)的、nosql数据库]</h6><h6 id="hbase架构图：要能手画出来"><a href="#hbase架构图：要能手画出来" class="headerlink" title="hbase架构图：要能手画出来"></a>hbase架构图：要能<strong>手画</strong>出来</h6><p><img src="http://m.qpic.cn/psb?/V11BXxlE33Kp9F/ynWG7DnR777pXkx0IGWDtEit4H6y7VkXIgYmJDtxY48!/b/dPMAAAAAAAAA&amp;bo=EAUIAwAAAAARBy4!&amp;rf=viewer_4" alt=""></p>
<h6 id="HBase没有单节点故障-因为zookeeper-，可以有多个Hmaster，跟namenode一样，同一时刻只有一个hmaster在工作"><a href="#HBase没有单节点故障-因为zookeeper-，可以有多个Hmaster，跟namenode一样，同一时刻只有一个hmaster在工作" class="headerlink" title="**HBase没有单节点故障(因为zookeeper)，可以有多个Hmaster，跟namenode一样，同一时刻只有一个hmaster在工作"></a>**HBase没有单节点故障(因为zookeeper)，可以有多个Hmaster，跟namenode一样，同一时刻只有一个hmaster在工作</h6><h4 id="HBase的功能："><a href="#HBase的功能：" class="headerlink" title="HBase的功能："></a>HBase的功能：</h4><pre><code>*hadoop数据库:
    1.存储数据 
    2.检索数据
*和RDBMS[关系型数据库]相比：
    1.海量数据：数据条目数--上亿
    2.检索的速度：准时性、秒级别
*基于hdfs： hdfs的优势
    1.数据安全性[副本机制]
    2.普通商用PC server就ok
</code></pre><h5 id="1-Table中的所有行都是按照rowkey的字典序排列"><a href="#1-Table中的所有行都是按照rowkey的字典序排列" class="headerlink" title="1.Table中的所有行都是按照rowkey的字典序排列"></a>1.Table中的所有行都是按照rowkey的字典序排列</h5><h5 id="2-Table在行的方向上分割为多个Region"><a href="#2-Table在行的方向上分割为多个Region" class="headerlink" title="2.Table在行的方向上分割为多个Region"></a>2.Table在行的方向上分割为多个Region</h5><h5 id="3-Region是按照大小分割的，每个表开始只有一个region-会有一个starkey和endkey-前毕后包-，随着数据增多，region不断增大，当增大到一定阀值时，region就会等分为两个新的region，之后会有越来越多的region。"><a href="#3-Region是按照大小分割的，每个表开始只有一个region-会有一个starkey和endkey-前毕后包-，随着数据增多，region不断增大，当增大到一定阀值时，region就会等分为两个新的region，之后会有越来越多的region。" class="headerlink" title="3.Region是按照大小分割的，每个表开始只有一个region[会有一个starkey和endkey,前毕后包]，随着数据增多，region不断增大，当增大到一定阀值时，region就会等分为两个新的region，之后会有越来越多的region。"></a>3.Region是按照大小分割的，每个表开始只有一个region[会有一个starkey和endkey,前毕后包]，随着数据增多，region不断增大，当增大到一定阀值时，region就会等分为两个新的region，之后会有越来越多的region。</h5><h5 id="4-Region是HBase中分布式存储和负载均衡的最小单位，不同region分不到不同的RegionServer上"><a href="#4-Region是HBase中分布式存储和负载均衡的最小单位，不同region分不到不同的RegionServer上" class="headerlink" title="4.Region是HBase中分布式存储和负载均衡的最小单位，不同region分不到不同的RegionServer上."></a>4.Region是HBase中分布式存储和负载均衡的最小单位，不同region分不到不同的RegionServer上.</h5><h5 id="5-Region虽然是分布式存储的最小单元，但是不是存储的最小单元。"><a href="#5-Region虽然是分布式存储的最小单元，但是不是存储的最小单元。" class="headerlink" title="5.Region虽然是分布式存储的最小单元，但是不是存储的最小单元。"></a>5.Region虽然是分布式存储的最小单元，但是不是存储的最小单元。</h5><pre><code>存储的最小单元是cell，{rowkey,column,version}
        *唯一性
        *数据没有类型，以字节码形式存储

region由一个或多个store组成，每个store保存一个column family；
每个store又由一个memStore和0至多个storeFile组成；
memStore存储在内存中，storeFile存储在hdfs上
</code></pre><h6 id="hbase-旧版本的web监听端口-60010，新版本是16010"><a href="#hbase-旧版本的web监听端口-60010，新版本是16010" class="headerlink" title="hbase 旧版本的web监听端口 60010，新版本是16010"></a>hbase 旧版本的web监听端口 60010，新版本是16010</h6><h3 id="HBASE数据写入流程："><a href="#HBASE数据写入流程：" class="headerlink" title="HBASE数据写入流程："></a>HBASE数据写入流程：</h3><pre><code>put ---&gt; cell
    step0： 先进行记录 ---&gt;HLog 【WAL（write ahead logging:日志预写功能）】 loc：hdfs
            存储的log数据类型是sequenceFile
</code></pre><p>——- WAL的作用是防止写入内存时，region挂掉，数据丢失</p>
<pre><code>step1： 写入memStore     loc：内存
step2： 当内存达到一定阈值时，写入storeFile  ---&gt; loc： hdfs
</code></pre><h3 id="HBASE-用户读取数据流程："><a href="#HBASE-用户读取数据流程：" class="headerlink" title="HBASE 用户读取数据流程："></a>HBASE 用户读取数据流程：</h3><pre><code>1)先到memStore里面去读
2)然后到BlockCache里面读 --&gt; *每个RegionServer只有一个BlockCache*
3)最后到HFile里面读取数据
4)然后对数据进行Merge --&gt; 最后返回数据集
</code></pre><h4 id="MemSore和BlockCache"><a href="#MemSore和BlockCache" class="headerlink" title="MemSore和BlockCache"></a>MemSore和BlockCache</h4><pre><code>*HBase上的RegionServer的内存分为两部分：
    1.Memstore --&gt; 用来 写
        写请求会先写入Memstore，RegionServer会给每个Region提供一个Memstore，当Memstore写满64M以后，会启动flush舒心到磁盘。
    2.BlockCache --&gt; 用来读
        读请求先到Memstore中查询数据，查不到就到BlockCache中查询，再差不读奥就会到磁盘上读，并把读的结果放入BlockCache。
        BlockCache达到上限后，会启动淘汰机制，淘汰掉最老的一批数据
*在注重读取响应时间的场景下，可以将BlockCache设置大些，Memstore设置小些，以加大缓存的命中率。
</code></pre><h3 id="数据检索的三种方式："><a href="#数据检索的三种方式：" class="headerlink" title="数据检索的三种方式："></a>数据检索的三种方式：</h3><pre><code>1.get rowkey --- 最快的方式
2.scan range --- 用的最多的方式 【一般先range扫描，然后get】
3.scan ---全表扫描，基本不用
</code></pre><h4 id="HBase中有类似于RDBMS中Database的概念"><a href="#HBase中有类似于RDBMS中Database的概念" class="headerlink" title="HBase中有类似于RDBMS中Database的概念"></a>HBase中有类似于RDBMS中Database的概念</h4><pre><code>命名空间：
    *用户自定义的表的命名空间，默认情况下 ---&gt;  default
    *系统自带的元数据的表的命名空间 ---&gt; hbase
</code></pre><h3 id="HBase数据迁移"><a href="#HBase数据迁移" class="headerlink" title="HBase数据迁移"></a>HBase数据迁移</h3><pre><code>使用 MapReduce把文件生成hdfs上的HFile，然后进行bulk load into hbase table
</code></pre><h1 id="HBase表RowKey的设计-："><a href="#HBase表RowKey的设计-：" class="headerlink" title="**HBase表RowKey的设计**："></a><strong>**</strong>HBase表RowKey的设计<strong>**</strong>：</h1><h5 id="现实环境中出现的问题："><a href="#现实环境中出现的问题：" class="headerlink" title="**现实环境中出现的问题："></a>**现实环境中出现的问题：</h5><pre><code>*默认情况下创建一张HBase表，自动会为表创建一个Region [startkey,endkey) 前毕后包
    *无论在测试环境还是生产环境中，创建完表以后会往表中导入大量数据
        步骤：
            file/datas -&gt; HFile -&gt; bulk load into hbase table
        此时Region只有一个，而region是被RegionServer管理的，
        当导入数据量慢慢增大后Region就会被split成两个Region，
        但是此时RegionServer很可能就会挂掉，此时就会出现问题...

解决方案[举例]：
    创建表时，多创建一些Region(依据表的rowkey进行设计 + 结合业务)
        比如说：有5个region，他们被多个RegionServer管理
            再插入数据时，会向5个Region中分别插入数据，这样就均衡了
</code></pre><h5 id="具体解决方案："><a href="#具体解决方案：" class="headerlink" title="**具体解决方案："></a>**具体解决方案：</h5><p>表的RowKey设计中：</p>
<pre><code>**如何在海量数据中，查询到我想要的数据???
    核心思想：
        1.依据RowKey查询最快
        2.对RowKey进行范围查询range
        3.前缀查询  
            比如：startkey:15221467820_20180409000053 和 endkey:15221467828_20180419000053
            这时只会比较15221467820 和 15221467828 而后面的_2018.. 则不会进行匹配    
</code></pre><p>解决方法：</p>
<pre><code>a).HBase的预分区：
    Region的划分依赖于RowKey，预先预估一些RowKey(年月日时分秒)[最常用的就是这两种，其他的方法rowkey设计都不能自定义]
        1. create &apos;tb1&apos;,&apos;cf1&apos;,splits =&gt; [&apos;20180409000000&apos;,&apos;20180419000000&apos;,&apos;20180429000000&apos;]
        2. create &apos;tb1&apos;,&apos;cf1&apos;,splits_file =&gt; &apos;/root/data/logs-split.txt&apos;
           [这种情况就是把分段的rowkey写入了文件里]
    这样就分为了4个Region，因为它会把头和尾也算进去
b).根据业务来对RowKey的设计：
        举例：移动运营商电话呼叫查询详单：
            RowKey: 
                phone + time 
                15221467820_20180409010000
            infor: 
                上海  主叫   152216888888   30        国内通话 0.00
                area active opposite_phone talk_time model price 
        依据查询条件：
            phone + (start_time - end_time)
        代码：
            scan 
                startrow
                    15221467820_20180409000000
                stoprow
                    15221467820_20180419000000
    保证了实时性
</code></pre><h3 id="HBase数据存储二级索引-索引表-的设计以及数据同步解决方案："><a href="#HBase数据存储二级索引-索引表-的设计以及数据同步解决方案：" class="headerlink" title="HBase数据存储二级索引[索引表]的设计以及数据同步解决方案："></a>HBase数据存储二级索引[索引表]的设计以及数据同步解决方案：</h3><p>基于以上的移动运营商电话呼叫查询详单：</p>
<pre><code>二级索引表：
    RowKey:
        opposite_phone
    columnFamily对应的colume:
        主表的RowKey
主表和索引表的同步：
    &gt;&gt; phoenix 
            &gt;&gt; jdbc 方式才能同步
    &gt;&gt;先在solr里创建索引表
     solr   //在solr中创建索引表
            国外有个框架交 lily
                cloudera search 封装了lily，只要配置下cloudera
                cloudera search会在主表插入数据时，自动更新solr里的索引表
</code></pre><h2 id="HBase之-表的属性"><a href="#HBase之-表的属性" class="headerlink" title="HBase之 表的属性:"></a>HBase之 表的属性:</h2><h3 id="面试会问到：-每个RegionServer只有一个HLog和一个BlockCache"><a href="#面试会问到：-每个RegionServer只有一个HLog和一个BlockCache" class="headerlink" title="面试会问到：**每个RegionServer只有一个HLog和一个BlockCache"></a>面试会问到：**每个RegionServer只有一个HLog和一个BlockCache</h3><pre><code>1.HBase的表的压缩[HFile compression]--表的属性:
**在企业中通常使用snappy格式进行压缩，可以减少容量的存储，和减少io流，提高传输效率
    跟hive一样，需要一些编译jar包，然后放到lib的native里
    [这里使用软连接 ln -s /xx/xx /xx  具体看官方文档]，还有一些参数的配置，才能使用
        创建表的时候：
            create &apos;user&apos;,{NAME=&apos;cf1&apos;,COMPRESSION=&gt;&apos;SNAPPY&apos;}
2. HBase 标的属性：IN_MEMORY=&gt;&apos;false&apos;、BLOCKCACHE=&gt;&apos;true&apos;
        HBase为什么查询这么快 就是因为这些表的属性的存储机制！！
        通常我们自定义创建的表的相应列簇下的IN_MEMORY属性都是false!
        通过describe &apos;hbase:meta&apos;可以查询到 IN_MEMORY=&gt;&apos;true&apos; BLOCKCACHE =&gt; &apos;true&apos;,
        意为meta元数据存放于blockcache的inmemory内存中
            IN_MEMORY队列存放HBase的meta表元数据信息，因为meta存储了用户表的
            通常 BLOCKCACHE 这个属性的设置要慎用，比如我们查询后的数据后续还会用到这时可以设置为true
            如果后续用不到这些数据就要设置此属性为false
</code></pre><h4 id="HBase的Cache分等级："><a href="#HBase的Cache分等级：" class="headerlink" title="HBase的Cache分等级："></a>HBase的Cache分等级：</h4><pre><code>默认情况下：整个BlockCache的内存分配 
1.IN_MEMORY 1/4    in_memory 用于存储hbase的meta元数据信息    2.Single 1/4   single就是用的次数较少的数据
3.Muti    1/2          muti就是用的次数较多的数据
如果BlockCache的内存到达阈值，会先清理single然后清理muti，in_memory的内存不会被清理!
</code></pre><h3 id="HBase表的compaction"><a href="#HBase表的compaction" class="headerlink" title="HBase表的compaction"></a>HBase表的compaction</h3><h6 id="随着写入数据的不断增加，hbase会把小的hfile进行合并，以以减少IO查询次数，合并有两种："><a href="#随着写入数据的不断增加，hbase会把小的hfile进行合并，以以减少IO查询次数，合并有两种：" class="headerlink" title="随着写入数据的不断增加，hbase会把小的hfile进行合并，以以减少IO查询次数，合并有两种："></a>随着写入数据的不断增加，hbase会把小的hfile进行合并，以以减少IO查询次数，合并有两种：</h6><pre><code>1.minor compaction
    Minor Compaction是指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，
    在这个过程中不会处理已经Deleted或Expired的Cell。一次Minor Compaction的结果是更少并且更大的StoreFile。
2.major compaction
    Major Compaction是指将所有的StoreFile合并成一个StoreFile，这个过程还会清理三类无意义数据：被删除的数据、TTL过期数据、版本号超过设定版本号的数据。另外，一般情况下，Major Compaction时间会持续比较长，会阻塞数据的吸入和查询!!!，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发Major Compaction功能，改为手动在业务低峰期触发。
</code></pre><h4 id="HBase和Hive集成："><a href="#HBase和Hive集成：" class="headerlink" title="HBase和Hive集成："></a>HBase和Hive集成：</h4><pre><code>此时实质上Hive就是HBase的一个客户端!
应用场景：
    日志文件 --&gt; hive --&gt; hive-hbase-table --&gt; insert .. select ...
</code></pre><h4 id="电商订单查询之HBase："><a href="#电商订单查询之HBase：" class="headerlink" title="电商订单查询之HBase："></a>电商订单查询之HBase：</h4><pre><code>1.用户下单后--&gt;存到RDBMS[关系型数据库]中 即未完成的订单
2.订单完成后--&gt;数据迁移到HBase中

查询比如三个月内的订单：
 1.主表[订单显示表]：
    rowkey: userid_orderCreateTime_orderId  
    cfname: orderInfor
    [本来userid+orderCreateTime就可以保证唯一性，加orderId的原因是为了二次查询]
 2.订单详情表:
     rowkey: orderId_orderItemId
    cfname: itemInfor
 3.索引表：
     比如用户输入订单号：我们后台Redis或者MongoDB里会有相对应的订单编码
     获取到订单编码然后到索引表中去查
         索引表的rowkey：订单编号 column: 主表的rowkey
         就可以到hbase主表中查询订单
</code></pre><h5 id="补充文件类型-tsv-tab-csv-comma-："><a href="#补充文件类型-tsv-tab-csv-comma-：" class="headerlink" title="补充文件类型 .tsv[tab] .csv[comma]："></a>补充文件类型 .tsv[tab] .csv[comma]：</h5><pre><code>user.tsv tsv后缀格式的文件：每行数据以tab 制表符分割的 
user.csv csv后缀格式的文件：每行数据以逗号分割的
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-DMP" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/04/05/DMP/" class="article-date">
  	<time datetime="2018-04-05T13:29:28.000Z" itemprop="datePublished">2018-04-05</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/05/DMP/">
        dmp介绍
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>dmp</p>
<p>（数据管理平台）<br> 编辑<br>DMP(Data Management Platform)数据管理平台，是把分散的多方数据进行整合纳入统一的技术平台，并对这些数据进行标准化和细分，让用户可以把这些细分结果推向现有的互动营销环境里的平台。<br>中文名<br>数据管理平台<br>外文名<br>Data Management Platform<br>释    义<br>数据进行整合纳入统一的技术平台<br>简    称<br>DMP<br>目录<br>.    1 作用<br>.    2 类型<br>作用<br>编辑<br>•能快速查询、反馈和快速呈现结果<br>•能帮助客户更快进入到市场周期中<br>•能促成企业用户和合作伙伴之间的合作<br>•能深入的预测分析并作出反应<br>•能带来各方面的竞争优势<br>•能降低信息获取及人力成本<br>类型<br>编辑<br>1、结构化的数据，比如Oracle数据库数据等；<br>　　2、非结构化的数据，比如各种文件、图像、音频等数据，等等。<br>　　结构化数据（即数据库数据）在当今的信息系统中占据最核心、最重要的位置。结构化数据从产生―使用―消亡这样一个完整过程的管理，就是数据生命周期管理（所谓的ILM）。<br>核心元素包括：<br>•数据整合及标准化能力：采用统一化的方式，将各方数据吸纳整合。<br>•数据细分管理能力：创建出独一无二、有意义的客户细分，进行有效营销活动。<br>•功能健全的数据标签：提供数据标签灵活性，便于营销活动的使用。<br>•自助式的用户界面：基于网页web界面或其他集成方案直接获取数据工具，功能和几种形式报表和分析。<br>•相关渠道环境的连接：跟相关渠道的集成，包含网站端、展示广告、电子邮件以及搜索和视频，让营销者能找到、定位和提供细分群体相关高度的营销信息。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2018 rongyuewu
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>